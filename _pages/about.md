---
permalink: /
title: "ğŸ‘‹ Hello and welcome to my website!"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

My name is Shahnewaz Sakib and I am an Assistant Professor in the Department of Computer Science and Engineering at the University of Tennessee at Chattanooga.

Hereâ€™s a quick look at what I do and what I am passionate about:

- ğŸ§  **Trustworthy AI** â€“ Designing systems you can understand and rely on  
- ğŸ” **Privacy-Preserving Machine Learning** â€“ Securing data through differential privacy & federated learning  
- âš–ï¸ **Fairness in Algorithms** â€“ Mitigating bias in AI decision-making  
- ğŸ’¬ **Explainable AI** â€“ Making black-box models transparent and interpretable  
- ğŸ›¡ï¸ **AI Safety & Robustness** â€“ Defending against adversarial and unethical model behavior 

---

ğŸ§ª **Research Interests**
- AI Safety & Trustworthy AI  
- Privacy-Preserving Machine Learning  
- Privacy-Enhancing Technologies  
- Federated Learning  
- Fairness in Machine Learning  
- Explainable & Interpretable AI  
- Adversarial Robustness  

---

ğŸ§‘â€ğŸ« **Teaching**

I teach courses such as Advanced Database & Security, Advanced Topics in AI, and Biometrics & Cryptography, with a focus on hands-on, research-driven learning. See more on my [Teaching](/teaching/) page.  

---

ğŸ—ï¸ **Recent Highlights**
- *August 2025*: Our paper "Between Privacy and Utility: Navigating Inference Risks in De-Identified Health Data" was accepted to the IEEE EMBS BHI 2025. This is the first paper of my Ph.D. student Swati! 
- *July 2025*: Our paper "Trustworthy Medical Imaging with Large Language Models: A Study of Hallucinations Across Modalities" was accepted to the CVAMD Workshop at ICCV 2025 
- *June 2025*: Selected to serve as Technical Program Committee Chair for the IEEE DISTILL 2025 Workshop, co-located with IEEE TPS 2025
- *May 2025*: Awarded Ruth S. Holmberg Grant for the project titled Empowering the Next Generation of AI Security Leaders through Hands-on Research, Outreach, and Scalable Educational Models  
- *March 2025*: Our paper "Battling Misinformation: An Empirical Study on Adversarial Factuality in Open-Source Large Language Models" was accepted to the TrustNLP Workshop at NAACL 2025 
- *Dec 2024*: The paper "Information Leakage Measures for Imperfect Statistical Information: Application to Non-Bayesian Framework" was accepted in IEEE Transactions on Information Forensics and Security  
- *Oct 2024*: Received acceptance for our paper "Challenging Fairness: A Comprehensive Exploration of Bias in LLM-Based Recommendations" at the 2024 IEEE International Conference on Big Data
  
---

ğŸ¤ **Collaboration Opportunities**  
I am always happy to connect with fellow researchers, students, or industry collaborators interested in advancing responsible AI. Whether itâ€™s about research partnerships, mentoring opportunities, or just exchanging ideas, feel free to [reach out](mailto:ssakib1@utc.edu).
